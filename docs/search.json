[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hi,\nI’m a dreamer, fighter and an explorer who is not afraid to step out of my comfort zone and venture into any unknown territory. My name is Clinta Puthussery Varghese and I am currently pursuing my second semester as a graduate student in Statistics at Zicklin School of Business in the Baruch College, City University Of New York with an anticipated graduation in May 2026.\n\nMy aspiration is to become a Data Scientist. As beauty lies in the eyes of the beholder, so too does the power of data rest in the hands of the analyst. I am dedicated to equipping myself to work with messy data, uncover insights, and ultimately contribute to making the world a better place.\nI am currently interning at Weill Cornell Medicine in the Computational Biology Lab under Dr. Annalise Schweickart. Additionally, I serve as a Graduate Tutor, supporting courses such as STA 9708, [CIS 9650], and [CIS 9340]. I also hold a Graduate Teaching Assistant role under Professor Yu Yue in the Paul H. Chook Department of Information Systems and Statistics.\nIn my free time, I enjoy crafting, especially diamond art painting, and traveling to explore new places.\nFeel free to connect with me on LinkedIn."
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "Mini Project #1",
    "section": "",
    "text": "Mini Project #1: Analyzing Transit Data\n\n\n\n\n\n\nI. Introduction\nThis project is inspired from popular CityNerd Youtube channel’s presentation on Farebox Recovery. The main goal of this mini project is to explore, analyze, and interpret transit data from various sources to derive insights into ridership trends, agency performance, and the financial efficiency of transit systems for the year 2022.\nThe primary source of data is from National Transit Database\nThe datasets used in this analysis is from\n\nThe 2022 Annual Database Fare Revenues table\nThe latest Monthly Ridership tables\nThe 2022 Operating Expenses reports\n\nThe analysis primarily focuses on key financial and operational performance metrics, such as Vehicle Revenue Miles (VRM), Unlinked Passenger Trips (UPT), and Farebox Recovery Ratio (the ratio of total fares to expenses). Additional explorations focus on the most efficient transit modes and the busiest metropolitan areas.\n\n\nII. Data Preparation\n\nLoading Required Libraries\nTo begin, we load the necessary R libraries, primarily using the tidyverse package for data wrangling and DT for data visualization.\n\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nif (!require(\"DT\")) install.packages(\"DT\")\n\nLoading required package: DT\n\nlibrary(tidyverse)\nlibrary(DT)\n\n\n\nImporting Datasets\nWe imported three main datasets: Fare Revenue (FARES), Operating Expenses (EXPENSES), and Ridership Data (TRIPS, MILES). These were cleaned and filtered to remove irrelevant columns, resulting in a dataset that focuses on total fares, expenses, and VRM/UPT data.\n\nFARES &lt;- readxl::read_xlsx(\"~/STA9750-2024-FALL/2022 Fare Revenue.xlsx\")\nEXPENSES &lt;- readr::read_csv(\"~/STA9750-2024-FALL/2022_NTD_Annual_Data_-_Operating_Expenses__by_Function__20231102.csv\")\n\nRows: 3744 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): Agency, City, State, NTD ID, Organization Type, Reporter Type, UZA...\ndbl  (2): Report Year, UACE Code\nnum (10): Primary UZA Population, Agency VOMS, Mode VOMS, Vehicle Operations...\nlgl  (7): Vehicle Operations Questionable, Vehicle Maintenance Questionable,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nTRIPS &lt;- readxl::read_xlsx(\"~/STA9750-2024-FALL/July 2024 Complete Monthly Ridership (with adjustments and estimates)_240903.xlsx\", sheet=\"UPT\")\nMILES &lt;- readxl::read_xlsx(\"~/STA9750-2024-FALL/July 2024 Complete Monthly Ridership (with adjustments and estimates)_240903.xlsx\", sheet=\"VRM\")\n\n\n\nData Cleaning\nAfter importing the data, several unnecessary columns were dropped to keep the datasets focused on the required metrics (UPT, VRM, Expenses, etc.)\nTo extract monthly financials such as Total Fares and Expenses for each mode, A new dataset (FINANCIALS) is created by joining Fare Revenue (FARES), Operating Expenses (EXPENSES). It contains (NTD ID, Agency Name , Mode, Total Fares, Expenses)\n\n\n`summarise()` has grouped output by 'NTD ID', 'Agency Name'. You can override\nusing the `.groups` argument.\n`summarise()` has grouped output by 'NTD ID'. You can override using the\n`.groups` argument.\n\n\nSimilarly to extract monthly transits numbers such as Unlinked Passenger Trip and Vehicle Revenue Miles for each agency and mode, a new data set USAGE(USAGE) is created by joining TRIPS (TRIPS) and MILES (MILES). It contains (NTD ID,Agency ,UZA Name,Mode,3 Mode,month,UPT, VRM )\n\n\n\nIII Exploratory Data Analysis (EDA)\n\nSampling and Displaying Data\n\nUSAGE\nThe str(str) function is used to get an overview of the datatypes.\n\nstr(USAGE)\n\ntibble [281,010 × 8] (S3: tbl_df/tbl/data.frame)\n $ NTD ID  : int [1:281010] 1 1 1 1 1 1 1 1 1 1 ...\n $ Agency  : chr [1:281010] \"King County\" \"King County\" \"King County\" \"King County\" ...\n $ UZA Name: chr [1:281010] \"Seattle--Tacoma, WA\" \"Seattle--Tacoma, WA\" \"Seattle--Tacoma, WA\" \"Seattle--Tacoma, WA\" ...\n $ Mode    : chr [1:281010] \"DR\" \"DR\" \"DR\" \"DR\" ...\n $ 3 Mode  : chr [1:281010] \"Bus\" \"Bus\" \"Bus\" \"Bus\" ...\n $ month   : Date[1:281010], format: \"2002-01-01\" \"2002-02-01\" ...\n $ UPT     : num [1:281010] 135144 127378 136030 142204 144697 ...\n $ VRM     : num [1:281010] 746158 656324 726578 736975 746158 ...\n\n\nFor easier readability, the column names are renamed, for ex: UZA Name can be renamed as metro_area. I have decided to keep UPT and VRM as is since its harder to rename with its full abbreviation.\n\n\n\n\nTask 1\n\n\n\n\n\n\nCreating Syntatic Names\n\n\n\nRename a column: UZA Name to metro_area.\n\nUSAGE &lt;- rename(USAGE, \n               metro_area = `UZA Name`\n               )\n\n\n\n\n\nTASK 2\n\n\n\n\n\n\nRecoding the Mode column\n\n\n\nThe details for what each Mode represents were found in National Transit Database (NTD) Glossary\n\nUSAGE &lt;- USAGE |&gt;\n    mutate(Mode = case_when(\n        Mode == \"AR\" ~ \"Alaska Rail\",\n        Mode == \"CB\" ~ \"Commuter Bus\",\n        Mode == \"CC\" ~ \"Cable Car\",\n        Mode == \"CR\" ~ \"Commuter Rail\",\n        Mode == \"DR\" ~ \"Demand Response\",\n        Mode == \"FB\" ~ \"Ferryboat\",\n        Mode == \"HR\" ~ \"Heavy Rail\",\n        Mode == \"IP\" ~ \"Inclined Plane\",\n        Mode == \"LR\" ~ \"Light Rail\",\n        Mode == \"MB\" ~ \"Motor Bus\",\n        Mode == \"MG\" ~ \"Monorail/Automated Guideway\",\n        Mode == \"PB\" ~ \"Publico\",\n        Mode == \"RB\" ~ \"Bus Rapid Transit\",\n        Mode == \"SR\" ~ \"Streetcar Rail \",\n        Mode == \"TB\" ~ \"Trolleybus \",\n        Mode == \"TR\" ~ \"Aerial Tramway\",\n        Mode == \"VP\" ~ \"Vanpool\",\n        Mode == \"YR\" ~ \"Hybrid Rail\",\n        TRUE ~ \"Unknown\"\n    ))\n\n\n\nTo get an overview of the ridership data (USAGE), we sampled 1000 records and displayed them using an interactive datatable.\n\n\n\n\n\n\n\nFINANCIALS\n\nstr(FINANCIALS)\n\ntibble [1,173 × 5] (S3: tbl_df/tbl/data.frame)\n $ NTD ID     : num [1:1173] 1 1 1 1 1 1 1 1 2 2 ...\n $ Agency Name: chr [1:1173] \"King County Department of Metro Transit\" \"King County Department of Metro Transit\" \"King County Department of Metro Transit\" \"King County Department of Metro Transit\" ...\n $ Mode       : chr [1:1173] \"CB\" \"DR\" \"FB\" \"LR\" ...\n $ Total Fares: num [1:1173] 5216912 832327 1715265 29386480 56846337 ...\n $ Expenses   : num [1:1173] 0.00 6.05e+07 8.90e+06 0.00 6.72e+08 ...\n\n\nFor easier readability the Mode is recoded\nHere is the overview of the ridership data (FINANCIALS),\n\nFINANCIALS |&gt;  DT::datatable()\n\n\n\n\n\n\n\n\nTask 4\n\n\n\n\n\n\nAnswering Instructor Specified Questions with dplyr.\n\n\n\nA.Vehicle Revenue Miles (VRM) Analysis\n\nVRM refers to Vehicle Revenue Miles.\nIt is the miles that vehicles are scheduled to or actually travel while in revenue service. (total number of miles traveled by a vehicle while it is in service and generating revenue by transporting passengers. It is used in public transportation and transit systems to measure the productive service a vehicle provides.)\nVehicle revenue miles include: Layover / recovery time\nVehicle revenue miles exclude: Deadhead, Operator training,Vehicle maintenance testing, and Other non-revenue uses of vehicles.\n\n1.Which transit agency had the most total VRM?\n\n\n\n\nBy summarizing VRM across transit agencies from 2002 to 2024, (I created a function named table_creation to tables)\n\n\n\ntable_creation(\n  USAGE %&gt;%\n    group_by(Agency) %&gt;%\n    summarise(`total_VRM($/miles)` = sum(VRM)) %&gt;%\n    arrange(desc(`total_VRM($/miles)`)) %&gt;%\n    slice(1:3))\n\n\n\n\n\nThe transit agency with the highest VRM in the sample is identified as\nAgency: MTA New York City Transit with Total_VRM: 10.83 billion revenue miles\n\n2.Which transit mode had the most total VRM?\nSimilarly, the analysis was performed by transit mode and arranged in descending order.\n\n\ntable_creation(USAGE %&gt;%\n  group_by(Mode) %&gt;%\n  summarise(`total_VRM($/miles)` = sum(VRM)) %&gt;%\n  arrange(desc(`total_VRM($/miles)`) )|&gt; slice(1:3))\n\n\n\n\n\nThe transist Mode (Motor Bus) had the total VRM of (49.45 billion revenue miles)\n\n3.NYC Subway Ridership in May 2024\nTo analyze ridership on the NYC Subway, we filtered the data for Heavy Rail in May 2024 and retrieved UPT values:\n\n\ntable_creation(USAGE %&gt;%\n  filter(Mode == 'Heavy Rail' & str_detect(Agency, \"New York City\") & month == \"2024-05-01\") %&gt;%\n  select(Mode,UPT))\n\n\n\n\n\nThe monthly ridership of subway for month of May 2025 is total UPT of (180.46 million)\n\n\n4.NYC Subway Ridership Decline from April 2019 to April 2020\nA significant decline in ridership was observed between April 2019 and April 2020. The percentage decline was calculated, and the ridership trend was plotted:\n\n\n\n\n\n\n\n\n\n\nThe subway system experienced a 91.28% decline in ridership between April 2019 and April 2020.\nHowever, post-pandemic, ridership has been steadily increasing.However,with the rise of hybrid work culture, monthly UPT rides now show a fluctuating, zigzag pattern.\n\nQuestions that I explore by myself\n\n#1. Which are the top 5 metropolitan areas with the highest number of transit agencies?\n\n\ntable_creation(USAGE |&gt;group_by(metro_area)|&gt;\nsummarize(`number of agencies` =length(unique(Agency)))|&gt;\narrange(desc(`number of agencies`)) |&gt;\nslice(1:5))\n\n\n\n\n\nThere are 38 agencies operating in the NY–Jersey City–Newark, NY–NJ metro area and 22 agencies in the Los Angeles–Long Beach, CA region. Let’s focus on the NY–NJ area.\n\n#2 What type of Transist Modes are Offered by Agencies in NY-NJ Metro Area\n\n\n\n\n\n\n\nMost agencies in NY-NJ Metro area offers Bus services. Lets see how is the presence of each mode with in Agencies.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\n\nIt’s surprising to see that the Vanpool service is exclusively offered by NJT. Given the vastness of the NY-NJ metropolitan area, it would be beneficial to promote Vanpool services similar to how other major cities like the SF-LA area are doing.\n\n#3 Which Mode of transit achieved the highest Vehicle Revenue Miles (VRM) per trip each year.\n\nThe VRM per trip ratio provides valuable insights into agency efficiency. A lower ratio indicates higher vehicle utilization, meaning the agency is transporting more passengers per mile of service. Typically, urban areas tend to have lower VRM per trip ratios compared to rural areas.\nTo assess the efficiency of agencies in the NY–NJ metropolitan area, we calculated the ratio of VRM to Unlinked Passenger Trips (UPT). This ratio reflects how well transit systems are utilizing their vehicles in relation to passenger demand, with a lower VRM/UPT ratio indicating better efficiency.\n\n#Which Transist Mode is profitable in termns of VRM/UPT Ratio:\n\n\n\n\n\n\n\n\n\n\n\n\n## Table for mean of median VRM/UPT ratios for each mode in NY-NJ Metro Area Till 2024\n\n\n\n\n\n\nFerryboat service and heavy rail service has the lowest VRM/UPT ratio after factoring no-agencies contributing to the data, This means those modes have better operational efficiency in terms of ridership relative to miles driven. Since there is only 1 agency contributing to the bus rapid transist, it is hard to determine its universality.\n\n\n\n\nIV Financial and Usage Data Analysis\n\nCombining USAGE and FINANCIALS\nAnalysing some data about financial recovery\nThe USAGE and FINANCIALS datasets were combined, and as a threshold total UPT &gt; 400000 is been taken into consideration.\n\nUSAGE_AND_FINANCIALS_top|&gt;DT:: datatable()\n\n\n\n\n\n\n\n\n\nFarebox Recovery and Cost Efficiency in Transit Systems\n\n1. Transit System with the Highest Farebox Recovery For The Year 2022\n\nFarebox recovery is the ratio of Total Fares to Total Expenses, measuring how effectively fare revenue covers a transit system’s operational costs. It’s crucial for a transit agency to generate enough revenue from passengers to offset its operating expenses. A higher farebox recovery ratio reduces the agency’s reliance on alternative funding sources to keep the transit system running.\n\ntable_creation(USAGE_AND_FINANCIALS_top |&gt; \n  group_by(Agency, Mode) |&gt; \n  summarize(\n    fare_box_ratio = round(ifelse(`Total Fares` &gt; 0, `Total Fares`, NA_real_) / ifelse(Expenses &gt; 0, Expenses, NA_real_),2\n  )) |&gt; \n  arrange(desc(fare_box_ratio)) |&gt; \n  ungroup() |&gt; \n  slice(1:5))\n\n`summarise()` has grouped output by 'Agency', 'Mode'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\nAgency: Port Imperial Ferry Corporation\nMode: Ferry Boat\nFarebox Recovery Ratio: 1.43\nInteresting Facts about Port Imperial Ferry’s Role\nIn 2022, the system with the highest farebox recovery ratio was the Port Imperial Ferry Corporation.\n\n\nPrime Location: Port Imperial terminal, located in Weehawken, New Jersey, connects commuters from New Jersey’s Hudson River waterfront to key locations in Manhattan. It is a crucial transportation link, especially for daily commuters.\n\nIntermodal Hub: It is also part of an intermodal hub, with connections to New Jersey Transit’s Hudson-Bergen Light Rail. This makes it easier for commuters to switch transit modes, enhancing the system’s convenience.\n\nTime-Saving Option: Their primary customers are daily commuters as it is often faster than other transit modes during rush hours, avoiding heavy traffic on bridges and tunnels, making it a preferred option for those seeking efficiency.\n\nSummary: Port Imperial Ferry’s high farebox recovery is driven by its limited competition, strategic docking agreements, loyal commuter base, and efficient cost management, allowing the service to generate significant revenue relative to its operational costs.\n\n\n\n2. Transit System with the Lowest Expenses per Unlinked Passenger Trip (UPT)\n\nExpenses per UPT measure the cost efficiency of a transit system, indicating how much the agency spends to serve per unlinked passenger trip.\n\ntable_creation(USAGE_AND_FINANCIALS_top |&gt; \n  group_by(Agency, Mode) |&gt; \n  summarize(\n    expenses_per_UPT = round(ifelse(Expenses &gt; 0, Expenses, NA_real_) / total_UPT\n  ,2)) |&gt; \n  arrange(expenses_per_UPT) |&gt; \n  ungroup() |&gt; \n  slice(1:5))\n\n\n\n\n\nAgency: North Carolina State University\nMode: Motor Bus\nExpenses per UPT: 1.18 $/ride\n\n\nWhy NCSU’s Motorbus System is Profitable?\n\nCampus Size: North Carolina State University’s main campus spans over 2,000 acres. This vast area creates the need for an internal transportation network to efficiently connect different parts of the university.\nTransportation Master Plan: NCSU has a well-structured Transportation Master Plan aimed at improving and optimizing its transportation network. This plan includes strategies to enhance route efficiency, reduce congestion, and ensure the system meets the growing demands of the campus population.\nInstitutional Support and Subsidies: NCSU likely subsidizes a portion of the motor bus system’s operating costs, which helps keep operational expenses lower. University funding or student fees may cover some costs, reducing the financial burden on passengers while keeping fares affordable, if not free.\nHigh Ridership: With a high volume of students and staff commuting daily, the system benefits from economies of scale. High passenger volume distributes operational costs across more riders, making the cost per trip lower, and ensuring the bus system operates efficiently.\nFocused Cost Management: NCSU’s internal control over the transportation system allows for focused cost management. With optimized vehicle maintenance, route planning, and operational schedules, the motor bus system is kept cost-efficient, ensuring its financial sustainability.\nSummary: NCSU’s motor bus system is profitable due to the combination of a large and spread-out campus, optimized and efficient route planning, institutional subsidies, and high ridership levels. This strategic approach, combined with NCSU’s Transportation Master Plan, ensures that the system operates at a low cost, making it not only cost-efficient but also potentially profitable.\n\n\n3. Transit System with the Highest Total Fares per UPT\n\nThe highest total fares per UPT indicate the system that generates the most fare revenue per passenger trip.\n\ntable_creation(USAGE_AND_FINANCIALS_top |&gt; \n  group_by(Agency, Mode) |&gt; \n  summarize(\n    totalfares_per_UPT = round(ifelse(`Total Fares` &gt; 0, `Total Fares`, NA_real_) / total_UPT\n  ,2)) |&gt; \n  arrange(desc(totalfares_per_UPT)) |&gt; \n  ungroup() |&gt; \n  slice(1:5))\n\n\n\n\n\nAgency: Hampton Jitney, Inc\nMode: Commuter Bus\nFares per UPT: 41.3 $/mile\nHampton Jitney is a commuter bus company.  Their Three primary routes from the east end of Long Island (The Hamptons and the North Fork) to New York City. Hampton Jitney also operates charter and tour services, along with local transit bus service in eastern Suffolk County under contract with Suffolk County Transit.\n\n\n\nWhy Hampton Jitney, Inc. has the highest fare per UPT?\n\nWealthy Customer Base : The Hampton Jitney serves affluent passengers traveling between New York City and the Hamptons, a popular destination for wealthy individuals. These passengers are generally less sensitive to price and are willing to pay premium fares for a convenient, comfortable ride.\n\nPrivate Agency : As a private transportation service, Hampton Jitney is not bound by government fare controls or subsidies. This allows the agency to charge market-based fares that reflect the demand and exclusive nature of the service.\n\nPremium Service : The Hampton Jitney offers luxury features such as comfortable seating, Wi-Fi, and direct routes, which justify the higher fare prices. Customers are paying not just for transportation, but for an upscale, stress-free experience.\nConvenient and Direct Routes: The bus service offers direct transportation from Manhattan to the Hamptons, saving passengers the hassle of driving or taking multiple transfers on public transportation. This convenience is a major factor in the willingness of passengers to pay higher fares.\nSeasonal Demand: The Hamptons is a popular summer destination, and during peak seasons, demand for transportation to and from the area skyrockets. Hampton Jitney can charge premium fares during these high-demand periods, further increasing their fare per UPT.\n\nConclusion: Hampton Jitney’s high fare per ride is driven by its affluent customer base, premium service offerings, convenient routes, and its ability to charge market-driven prices as a private agency. The high fare reflects the value that customers place on convenience and comfort, particularly when traveling to a luxury destination like the Hamptons.\n\n\n\n4. Transit System with the Lowest Expenses per Vehicle Revenue Mile (VRM)\n\nThis metric shows the agency that operates most efficiently in terms of expenses for each mile their vehicles are in service.\n\ntable_creation(USAGE_AND_FINANCIALS_top |&gt; \n  group_by(Agency, Mode) |&gt; \n  summarize(\n    expenses_per_VRM = round(ifelse(Expenses &gt; 0, Expenses, NA_real_) / ifelse(total_VRM &gt; 0, total_VRM, NA_real_),2)\n  ) |&gt; \n  arrange(expenses_per_VRM) |&gt; \n  ungroup() |&gt; \n  slice(1:5))\n\n\n\n\n\nAgency: Metropolitan Transportation Commission\nMode: Vanpool\nExpenses per VRM: 0.445 $/mile\n**Metro-Area*:** San Francisco--Oakland, CA\nThe Bay Area Vanpool Program, managed by the MTC, supports groups of 7 to 15 commuters traveling together with an unpaid driver.\n\nAccording to the Berkleyside, Casual Carpool was a Bay Area tradition before COVID. Post Covid, longtime riders and drivers who want to revive casual carpool are finding it difficult to reestablish the famously organic tradition. But since many people are returning to work and seeking efficient ways to travel, and it’s interesting to observe that there’s a slow resurgence of this informal carpooling tradition.\n\n\nWhy MTC’S Vanpool reduce expenses per Vehicle Revenue Mile (VRM)?\n\nCost-Effective Commute : Vanpooling is often more economical than driving alone, with participants sharing the costs of fuel, tolls, and maintenance. This can lead to significant savings for commuters.\n\nSustainable Way : By reducing the number of single-occupancy vehicles on the road, vanpools help decrease traffic congestion and lower greenhouse gas emissions, contributing to a more sustainable environment.\n\nVanpool Rewards : The MTC actively promotes vanpooling as part of its broader strategy to enhance public transportation options and reduce reliance on individual car travel. Each counties provides different benefits including pre-tax benefits, discounted parking permits and subsidies for commuter vanpoolers\n\n\n\n5. Transit System with the Highest Total Fares per VRM\n\n\nThe highest total fares per VRM represent the system that generates the most fare revenue for each mile that its vehicles are in service.\n\n\ntable_creation(USAGE_AND_FINANCIALS_top |&gt; \n  group_by(Agency, Mode) |&gt; \n  summarize(\n    fares_per_VRM = round(ifelse(`Total Fares` &gt; 0, `Total Fares`, NA_real_) / ifelse(total_VRM &gt; 0, total_VRM, NA_real_),2)\n  ) |&gt; \n  arrange(desc(fares_per_VRM)) |&gt; \n  ungroup() |&gt; \n  slice(1:5))\n\n\n\n\n\nAgency: Jacksonville Transportation Authority\nMode: Ferryboat\nFares per VRM: 157.70 $/mile\nThe St. Johns River Ferry is an important transportation link, providing service across the St. Johns River and facilitating commuter travel.\n\n\nWhat do you believe to be the most efficient transit system in the country?\nIn my view, the most efficient transit system is one that prioritizes the needs of the community rather than focusing solely on generating revenue. Such a system aims to provide reliable and accessible transportation options that serve the public effectively. Among the various transit modes analyzed, I find ferryboats to be particularly efficient, especially in terms of their overall Vehicle Revenue Miles (VRM) to Unlinked Passenger Trips (UPT) ratio. This efficiency indicates that ferryboats are capable of serving a substantial number of passengers relative to the distance traveled, making them a viable option for enhancing urban mobility.\nAdditionally, when considering cost-effectiveness and environmental sustainability, the Vanpool mode emerges as the best option. Vanpools not only reduce operational costs but also contribute positively to the environment by minimizing the number of individual vehicles on the road. By consolidating passengers into fewer vehicles, Vanpools can significantly decrease carbon emissions and traffic congestion, promoting a greener transit solution.\nUltimately, an efficient transit system should not merely aim for financial gain but should instead focus on fulfilling the transportation needs of its users while fostering sustainable practices. By investing in transit options like ferryboats and Vanpools, cities can create a more effective and environmentally friendly transportation network that benefits both the community and the planet.\n\n\nAppendix\nAdditional data and visualizations can be provided upon request, including full code listings and intermediate data tables."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "mp2",
    "section": "",
    "text": "I.Introduction\nHollywood has often used familiar strategies to attract audiences, like making movies based on real-life stories, adapting books or games, or working with popular intellectual properties. However, in recent years, movie theaters have seen fewer big box office hits, and audiences aren’t flocking to see the latest films as they used to.\nThis project aims to find new movie ideas by analyzing data from the Internet Movie Database (IMDb). By looking at what made past movies successful, identifying top actors and directors,popular genres.. we hope to give Hollywood executives useful insights for creating movies that can draw audiences back to theaters.\n\n\nII.Data Preparation\nThe following packages are used for this analysis: dplyr, tidyr, DT, ggplot2 and tidyverse,gganimate , scales. If these packages have not been installed in the system, they can be with the following code:\n\n1.Loading Required Libraries\nTo begin, we load the necessary R libraries, primarily using the tidyverse package for data wrangling and DT for data visualization.\n\n\nCode\nif(!require(\"ggplot2\")) install.packages(\"ggplot2\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"DT\")) install.packages(\"DT\")\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(ggplot2)\n\n\nI have also created a function for interactive table creation\n\n\nCode\ntable_creation&lt;-function(x){\n  datatable(x, \n            options = list(\n              searching = FALSE,   # Removes the search bar\n              pageLength = 10,      # Optional: Set the number of rows displayed per page\n              lengthChange = FALSE,# Removes the option to change the number of rows displayed\n              dom = 't'\n            ),\n            filter = 'none'\n  )  \n}\n\n\n\n\n2.Data Loading\n\n\nCode\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\n\n\n\nCode\nNAME_BASICS &lt;- get_imdb_file(\"name.basics\")\n#write.csv(NAME_BASICS, \"~/STA9750-2024-FALL/NAME_BASICS.csv\",row.names=TRUE,col.names = TRUE )\n\n\n\n\nCode\nTITLE_BASICS&lt;- get_imdb_file(\"title.basics\")\n#write.csv(TITLE_BASICS, \"~/STA9750-2024-FALL/TITLE_BASICS.csv\",row.names=TRUE,col.names = TRUE )\n\n\n\n\nCode\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\nwrite.csv(TITLE_EPISODES, \"~/STA9750-2024-FALL/TITLE_EPISODES.csv\",row.names=TRUE,col.names = TRUE )\n\n\n\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\n\n\n\nCode\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\n\n\n\n\nCode\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\n\n\n\n3.Data Sub-Sampling\nFor our NAME_BASICS table, we’ll restrict our attention to people with at least two “known for” credits.\n\nglimpse(NAME_BASICS)\n\nRows: 3,180,842\nColumns: 7\n$ X                 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;int&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;int&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\n\n\nCode\nTITLE_RATINGS |&gt;\n    ggplot(aes(x=numVotes)) + \n    geom_histogram(bins=30) +\n    xlab(\"Number of IMDB Ratings\") + \n    ylab(\"Number of Titles\") + \n    ggtitle(\"Majority of IMDB Titles Have Less than 100 Ratings\") + \n    theme_bw() + \n    scale_x_log10(label=scales::comma) + \n    scale_y_continuous(label=scales::comma)\n\n\n\n\n\n\n\n\n\n\n\nCode\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n      5      11      26     101 2945751 \n\n\n\n\nCode\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\n\n\n\nCode\nglimpse(NAME_BASICS)\n\n\nRows: 3,180,842\nColumns: 7\n$ X                 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;int&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;int&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\n\n\nCode\nglimpse(TITLE_BASICS)\n\n\nRows: 837,371\nColumns: 11\n$ X              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000001\", \"tt0000002\", \"tt0000002\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Carmencita\", \"Le clown et ses chiens\", \"…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Carmencita\", \"Le clown et ses chiens\", \"…\n$ isAdult        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;int&gt; 1894, 1894, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1…\n$ endYear        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\",…\n$ runtimeMinutes &lt;chr&gt; \"1\", \"1\", \"5\", \"5\", \"5\", \"5\", \"5\", \"12\", \"12\", \"1\", \"1\"…\n$ genres         &lt;chr&gt; \"Documentary\", \"Short\", \"Animation\", \"Short\", \"Animatio…\n$ genre_cleaned  &lt;chr&gt; \"Documentary\", \"Others\", \"Animation\", \"Others\", \"Animat…\n\n\n\n\nCode\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS1 &lt;- TITLE_PRINCIPALS1 |&gt; semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\n\n\n\nIII. Initial Exploration\n\n\n\n\n\n\nTask 1: Column Type Correction\n\n\n\n\n\n\nCorrect the column types of the TITLE tables using a combination of mutate and the coercion functions as.numeric and as.logical..\n\n\nCode\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(startYear = as.numeric(startYear))\nTITLE_BASICS&lt;-TITLE_BASICS |&gt; separate_longer_delim(genres, \",\") \nglimpse(TITLE_BASICS)\n\n\nRows: 837,371\nColumns: 11\n$ X              &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ tconst         &lt;chr&gt; \"tt0000001\", \"tt0000001\", \"tt0000002\", \"tt0000002\", \"tt…\n$ titleType      &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"…\n$ primaryTitle   &lt;chr&gt; \"Carmencita\", \"Carmencita\", \"Le clown et ses chiens\", \"…\n$ originalTitle  &lt;chr&gt; \"Carmencita\", \"Carmencita\", \"Le clown et ses chiens\", \"…\n$ isAdult        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ startYear      &lt;dbl&gt; 1894, 1894, 1892, 1892, 1892, 1892, 1892, 1892, 1892, 1…\n$ endYear        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\",…\n$ runtimeMinutes &lt;chr&gt; \"1\", \"1\", \"5\", \"5\", \"5\", \"5\", \"5\", \"12\", \"12\", \"1\", \"1\"…\n$ genres         &lt;chr&gt; \"Documentary\", \"Short\", \"Animation\", \"Short\", \"Animatio…\n$ genre_cleaned  &lt;chr&gt; \"Documentary\", \"Others\", \"Animation\", \"Others\", \"Animat…\n\n\n\n\nCode\nrelevant_genres &lt;- c(\"Action\", \"Comedy\", \"Drama\", \"Horror\", \"Romance\", \"Thriller\", \"Adventure\", \"Animation\", \"Biography\", \"Crime\", \"Documentary\",\"Musical\",\"Romance\",\"Sci-Fi\")\n\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n  mutate(genre_cleaned = case_when(\n    genres %in% relevant_genres ~ genres,\n    TRUE ~ \"Others\"  # Assign \"Others\" to all non-relevant genres\n  ))\n\n\n\n\nCode\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear),\n           deathYear = as.numeric(deathYear))\nglimpse(NAME_BASICS)\n\n\nRows: 3,180,842\nColumns: 7\n$ X                 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0072308,tt0050419,tt0053137,tt0027125\", \"tt003738…\n\n\n\n\nCode\nTITLE_CREW&lt;-TITLE_CREW |&gt; separate_longer_delim(directors, \",\")\nglimpse(TITLE_CREW)\n\n\nRows: 550,846\nColumns: 4\n$ X         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ tconst    &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt00000…\n$ directors &lt;chr&gt; \"nm0005690\", \"nm0721526\", \"nm0721526\", \"nm0721526\", \"nm00056…\n$ writers   &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N…\n\n\n\n\nCode\nglimpse(TITLE_EPISODES)\n\n\nRows: 3,012,210\nColumns: 5\n$ X             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ tconst        &lt;chr&gt; \"tt0045960\", \"tt0046855\", \"tt0048378\", \"tt0048562\", \"tt0…\n$ parentTconst  &lt;chr&gt; \"tt0044284\", \"tt0046643\", \"tt0047702\", \"tt0047768\", \"tt0…\n$ seasonNumber  &lt;int&gt; 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 8, 1, 10, 6, 2, 8, 4…\n$ episodeNumber &lt;int&gt; 3, 4, 6, 10, 4, 20, 5, 2, 20, 6, 2, 3, 2, 10, 17, 5, 1, …\n\n\nCode\nTITLE_EPISODES&lt;-TITLE_EPISODES|&gt;mutate(\n            seasonNumber=as.numeric(seasonNumber),\n           episodeNumber=as.numeric(episodeNumber))\n\n\n\n\nCode\nglimpse(TITLE_PRINCIPALS1)\n\n\nRows: 6,598,225\nColumns: 7\n$ X          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ tconst     &lt;chr&gt; \"tt0000001\", \"tt0000001\", \"tt0000001\", \"tt0000001\", \"tt0000…\n$ ordering   &lt;int&gt; 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 1, 2, 3, 4,…\n$ nconst     &lt;chr&gt; \"nm1588970\", \"nm0005690\", \"nm0005690\", \"nm0374658\", \"nm0721…\n$ category   &lt;chr&gt; \"self\", \"director\", \"producer\", \"cinematographer\", \"directo…\n$ job        &lt;chr&gt; \"\\\\N\", \"\\\\N\", \"producer\", \"director of photography\", \"\\\\N\",…\n$ characters &lt;chr&gt; \"[\\\"Self\\\"]\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\N\", \"\\\\…\n\n\n\n\nCode\nglimpse(TITLE_RATINGS)\n\n\nRows: 372,896\nColumns: 4\n$ X             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ tconst        &lt;chr&gt; \"tt0000001\", \"tt0000002\", \"tt0000003\", \"tt0000004\", \"tt0…\n$ averageRating &lt;dbl&gt; 5.7, 5.6, 6.5, 5.4, 6.2, 5.0, 5.4, 5.4, 5.4, 6.8, 5.2, 7…\n$ numVotes      &lt;int&gt; 2088, 282, 2095, 183, 2831, 195, 888, 2235, 213, 7705, 3…\n\n\n\n\n\n\n\n\nTask 2: Instructor-Provided Questions\n\n\n\n\n\n\n\n1.How many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nCode\ntable(TITLE_BASICS$titleType)\n\n\n\n       movie        short    tvEpisode tvMiniSeries      tvMovie     tvSeries \n      266029        39986       394516        12413        29156        60368 \n     tvShort    tvSpecial        video    videoGame \n        1052         4388        17491        11972 \n\n\nI write a functioncount_title to identify the project type and count.\n\n\nCode\ncount_title&lt;-function(x){\n  word&lt;-x\n  count&lt;-sum(grepl(word,TITLE_BASICS$titleType,ignore.case = TRUE))\n  return(count)                        \n}\n\n\n\n\nCode\nmovie_count&lt;-count_title(\"movie\")\nseries_count&lt;-count_title(\"series\")\nepisode_count&lt;-count_title(\"episode\")\nprint(paste0(\"There are \", movie_count, \" movies, \", series_count, \" series and \", episode_count, \" episodes in the TITLE_BASICS dataset.\"))\n\n\n[1] \"There are 295185 movies, 72781 series and 394516 episodes in the TITLE_BASICS dataset.\"\n\n\n\n2.Who is the oldest living person in our data set?\n\nAccording to wikipedia, the oldest person alive in the world is of 1908 onwards. Hence, I keep checked for people who are born on 1908 and afterwards, and who doesn’t a death year\n\n\nCode\nNAME_BASICS|&gt;select(-knownForTitles)|&gt;\n  filter(birthYear==1908, is.na(deathYear))|&gt;\n  distinct(primaryName, .keep_all = TRUE)|&gt;select(primaryName,primaryProfession)|&gt;DT::datatable()\n\n\n\n\n\n\nThere are 111 individuals who were born in the year 1911.\n\n3.There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\n\n\n\nCode\nlibrary(DT)\n\nperfect_episode&lt;-TITLE_RATINGS|&gt;filter(averageRating==10.0,numVotes&gt;=200000)\n\nperfect_episode&lt;-perfect_episode|&gt; left_join(TITLE_EPISODES,by=c('tconst'='tconst'))\n\nperfect_episode&lt;-perfect_episode|&gt;left_join(TITLE_BASICS,by=c('tconst'='tconst'))\n\ntable_creation(perfect_episode|&gt;\n                 select(originalTitle,titleType,seasonNumber,episodeNumber,averageRating,numVotes)|&gt;distinct())\n\n\n\n\n\n\nThe perfect rated TV episode is “Ozymandias” which is the 14th Episode in Season 5 of Breaking Bad TV Series.\n\n4.What four projects is the actor Mark Hamill most known for? I wrote a function find_projects which takes actor_or_director name as a parameter and returns all the projects they have been part of.\n\nI began by joining the TITLE_RATINGS and TITLE_EPISODES datasets to create TITLE_BASICS_RATING_1 and TITLE_BASICS_RATING_2, using the tconst (title constants) as the key. This ensured that all relevant title ratings and episode information were combined.\nNext, I merged these two datasets into TITLE_RATING_EPISODE, arranged it by descending averageRating and numVotes, and removed duplicate entries to get a clean dataset for further analysis.\n\n\nCode\nlibrary(tidyverse)\nTITLE_BASICS_RATING_1&lt;-full_join(TITLE_RATINGS,TITLE_EPISODES|&gt;select(tconst),by=c(\"tconst\" = \"tconst\"))\nTITLE_BASICS_RATING_2&lt;-full_join(TITLE_RATINGS,TITLE_EPISODES|&gt;select(parentTconst)|&gt;rename(tconst=parentTconst),by=c(\"tconst\" = \"tconst\"))\nTITLE_RATING_EPISODE&lt;-bind_rows(TITLE_BASICS_RATING_1,TITLE_BASICS_RATING_2)\nTITLE_RATING_EPISODE&lt;-TITLE_RATING_EPISODE|&gt;\n  arrange(desc(averageRating),desc(numVotes))|&gt;distinct()\nrm(TITLE_BASICS_RATING_1)\nrm(TITLE_BASICS_RATING_2)\nsample_n(TITLE_RATING_EPISODE,100)|&gt;DT::datatable()\n\n\n\n\n\n\nI created the dataset ALL_TITLES by merging title information (such as primaryTitle, titleType, and startYear) with the TITLE_RATING_EPISODE. I filtered out any entries categorized under the genre “Others” to focus on specific genres.\n\n\nCode\n#|code-summary: \"Show the code\"\n\nALL_TITLES&lt;-full_join(\n  TITLE_BASICS|&gt;\n    select(tconst,primaryTitle,titleType,genres,genre_cleaned,startYear),\n  TITLE_RATING_EPISODE,by=c(\"tconst\" = \"tconst\"))|&gt;select(-genres)|&gt;filter(genre_cleaned!=\"Others\")\nsample_n(ALL_TITLES,100)|&gt;DT::datatable()\n\n\n\n\n\n\nI gathered crew information by combining TITLE_CREW (containing director data) and TITLE_PRINCIPALS1 (with principal actor information) to create ALL_CREW, which included both directors and actors. To link this data with individual crew members, I merged the ALL_CREW dataset with the NAME_BASICS dataset, which includes actors and directors known projects and names.\n\n\nCode\n#|code-summary: \"Show the code\"\nTITLE_RATINGS_CREW_1&lt;-ALL_TITLES|&gt;select(tconst)|&gt;full_join(TITLE_CREW|&gt;select(tconst,directors),by=c(\"tconst\"=\"tconst\"))|&gt;distinct()\n\nTITLE_RATING_CREW_2&lt;-ALL_TITLES|&gt;select(tconst)|&gt;full_join(TITLE_PRINCIPALS1|&gt;select(tconst,nconst),by=c(\"tconst\"=\"tconst\"))|&gt;distinct()\n\nALL_CREW=bind_rows(TITLE_RATINGS_CREW_1|&gt;rename(nconst=directors),TITLE_RATING_CREW_2)\nrm(TITLE_RATINGS_CREW_1,TITLE_RATING_CREW_2)\n\nsample_n(ALL_CREW,100)|&gt; DT::datatable()\n\n\n\n\n\n\n\n\nCode\n#|code-summary: \"Show the code\"\nlibrary(tidyverse)\nALL_CREW=ALL_CREW|&gt;full_join(NAME_BASICS|&gt;select(nconst,primaryName,knownForTitles),by=c(\"nconst\"=\"nconst\"))\nALL_CREW&lt;-ALL_CREW|&gt;distinct()\nsample_n(ALL_CREW,100)|&gt;DT::datatable()\n\n\n\n\n\n\nI developed a function called find_projects that takes the name of an actor or director as input (in this case, “Mark Hamill”). The function filters the combined dataset (ALL_CREW) to find all projects associated with the specified person, including those in the knownForTitles column. The function then searches for these titles in the ALL_TITLES dataset to return the relevant projects.\n\n\nCode\n#|code-summary: \"Show the code\"\nfind_projects&lt;-function(actor_or_director){\n  titles_1&lt;-ALL_CREW |&gt; \n    filter(str_detect(primaryName, actor_or_director))|&gt;\n    select(nconst,knownForTitles,tconst)\n  titles_1&lt;-titles_1|&gt;separate_longer_delim(knownForTitles, \",\") \n  titles&lt;-vctrs::vec_c(titles_1$tconst|&gt;unique(),titles_1$knownForTitles|&gt;unique())|&gt;unique()\n\n found_projects&lt;-ALL_TITLES|&gt;filter(tconst %in% titles)\n   \n \n  \n return(found_projects)\n}\n\n\n\n\nCode\nname=\"Mark Hamill\"\nfind_projects(name)|&gt;select(primaryTitle,averageRating,numVotes)|&gt;distinct()|&gt;\n  arrange(desc(numVotes),desc(averageRating))|&gt;slice(1:75)|&gt;DT::datatable()\n\n\n\n\n\n\nBased on the above analysis and functions, we find that Mark Hamill is famously known for the following four film/TV Series projects, which are Star Wars movies, The Batman Animated movies,Scooby Doo Animated Series and Avatar:The Last Airbender animated series. Mark Hamill is prestigious to be included in these film projects as they are highly rated and loved by the fans, especially Star Wars movies, The Last Airbender Animated Series and the Batman Animated movies.\n\n5.What TV series, with more than 12 episodes, has the highest average rating?\n\n\n\nCode\nSERIES&lt;-right_join(ALL_TITLES,TITLE_EPISODES|&gt;filter(episodeNumber&gt;12)|&gt;distinct(parentTconst,.keep_all = TRUE)|&gt;select(-tconst),by=c(\"tconst\"=\"parentTconst\"))\n\n\n\n\nCode\nSERIES|&gt;arrange(desc(numVotes),desc(averageRating))|&gt;select(primaryTitle,averageRating,numVotes)|&gt;distinct()|&gt;slice(1:10)\n\n\n            primaryTitle averageRating numVotes\n1           Breaking Bad           9.5  2211754\n2                Friends           8.9  1109937\n3       The Walking Dead           8.1  1106790\n4    The Big Bang Theory           8.1   885395\n5  How I Met Your Mother           8.3   741692\n6             The Office           9.0   738180\n7       Better Call Saul           9.0   679646\n8                   Lost           8.3   612694\n9                Vikings           8.5   598444\n10          Prison Break           8.3   595806\n\n\nAs seen from the above table, Breaking Bad ranks the first among the top ten TV series, that has the highest number of votes and rated well by the critics. It deserves to be rated as the highest because of the thrilling intensity, it gives the viewers as well as the way they show each of the character development and growth through each of the episode and season.\n\n\nIV. Quantifying Success\n\n\n\n\n\n\n####Task 3\n\n\n\n\nDesign a ‘success’ measure for IMDb entries, reflecting both quality and broad popular awareness. Implement your success metric using a mutate operator to add a new column to the TITLE_RATINGS table.\n\nI created a new variable new_rating with Smoothing Formula: &gt;The new rating is calculated using a simple form of Bayesian average to account for the uncertainty in ratings with a low number of votes. The formula used is:\n\\[ new-rating=(averageRating×numVotes+1)/(numVotes+2) \\]\n\\[ new-rating= (numVotes+2)(averageRating×numVotes+1) \\]\n\nThe term averageRating * numVotes gives the total sum of the ratings. Adding 1 to the numerator is a form of smoothing to slightly increase ratings with low votes. Dividing by numVotes + 2 accounts for the additional “pseudo-votes” introduced by the smoothing factor.\n\n\n\nCode\nALL_TITLES&lt;-ALL_TITLES|&gt;mutate(new_rating=round((averageRating*numVotes+1)/(numVotes+2),3))\n\n\n\n1.Choose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\nI used the function identify_title to filter movies\n\n\nCode\nidentify_title&lt;-function(df,word){\n  x&lt;-df|&gt;filter(grepl(word,titleType,ignore.case = TRUE))\n  return(x)                     \n}\n\n\nhighest_top_50 function was developed to identify and retrieve the top 50 movies based on the number of votes and ratings. This function takes a dataframe as input, arranges the data in descending order by numVotes and new_rating, and returns the top 50 entries while excluding the columns averageRating, tconst, and titleType from the output. Next, the dataset movies_rated was generated by using the identify_title function to filter movie titles from the ALL_TITLES dataset, ensuring only distinct rows were included, and removing the genre_cleaned column. The highest_top_50 function was then applied to this dataset, and the result was passed to the table_creation function, which produced an interactive table using the DT package to display the top 50 movies based on votes and ratings.\n\n\nCode\nhighest_top_50&lt;-function(df)\n{\n  df|&gt;\n    arrange(desc(numVotes),desc(new_rating))|&gt;\n    slice(1:50)|&gt;\n    select(-averageRating,-tconst,-titleType)\n}\n\n\n\n\nCode\nlibrary(DT)\nmovies_rated&lt;-identify_title(ALL_TITLES,\"movie\")\ntable_creation(highest_top_50(movies_rated|&gt;select(-genre_cleaned)|&gt;distinct()))\n\n\n\n\n\n\n\n2.Choose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\nTo identify movies with a large number of IMDb votes but poor performance on the success metric, I sorted the movies_rated dataset by descending order of numVotes and filtered for movies with a new_rating of less than 5. The following code selects the top 10 movies fitting this criterion and excludes the columns tconst and titleType:\n\n\nCode\n# Sort by the new rating\ntable_creation(movies_rated |&gt; \n    arrange(desc(numVotes)) |&gt; \n    filter(new_rating&lt;5) |&gt; \n        select( -tconst, -titleType,-genre_cleaned)|&gt;slice(1:10)|&gt;distinct())\n\n\n\n\n\n\n\n3.Choose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\n\nCode\nlibrary(dplyr)\n# Function to get user input and find their projects\n#name &lt;- readline(prompt = \"Enter the actor or director name:\")\n\n\n# Assuming `find_projects()` is a function that takes a name and returns a data frame of projects\nname=\"Tom Hanks\"\nprojects1&lt;-find_projects(name)\n\n\n# Select relevant columns\nprojects1|&gt;select(primaryTitle,new_rating,numVotes)|&gt;distinct()|&gt;\n  arrange(desc(new_rating),desc(numVotes))|&gt;DT::datatable()\n\n\n\n\n\n\n\n\nCode\n#|code-summary: \"Show the code\"\nlibrary(dplyr)\nlibrary(ggplot2)\nprojects1 |&gt;\n  filter(new_rating &gt; median(averageRating)) |&gt;\n  group_by(genre_cleaned)|&gt;\n  summarize(count = n(), .groups = \"drop\")|&gt;\n  ggplot(aes(x = reorder(genre_cleaned, count), y = count, fill = genre_cleaned)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Genre\",\n    y = \"Number of Movies per Genre\",\n    fill = \"Genre\"\n  ) +\n  scale_fill_manual(\"Genres\",values = c(\"Documentary\" = \"#1f77b4\", \"Comedy\" = \"#ff7f0e\", \n                               \"Horror\" = \"#2ca02c\", \"Action\" = \"#d62728\", \n                               \"Adventure\" = \"#9467bd\", \"Crime\" = \"#8c564b\", \n                               \"Animation\" = \"#e377c2\", \"Drama\" = \"#7f7f7f\", \n                               \"Romance\" = \"#bcbd22\", \"Sci-Fi\" = \"#17becf\",\n                               \"Thriller\" = \"#1ae4e2\", \"Biography\" = \"#377eb8\",\n                               \"Musical\" = \"#4daf4a\"))+\n  ggtitle(\"Tom Hank's Successful Projects \\n Rating &gt; Median(Rating)\") +\n  theme(\n    legend.position = \"bottom\",\n    axis.text.x = element_blank(),\n    plot.title = element_text(hjust = 0.5)  # centers the title\n  )\n\n\n\n\n\n\n\n\n\n\n4.Perform at least one other form of ‘spot check’ validation.\n\n\n5.Come up with a numerical threshold for a project to be a ‘success’; that is, determine a value such that movies above are all “solid” or better.\n\nThe Genres column has multiple values, hence cleaning it a bit.\n\n\nCode\n summary(ALL_TITLES$numVotes)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    100     178     380    4918    1189 2945751 \n\n\nThe data appeared right-skewed, indicating that most movies had relatively low vote counts while a few received a significantly higher number of votes.\nTo better analyze the data, I arranged the ALL_TITLES dataset by both numVotes and new_rating. I then divided the dataset into four quantiles based on the numVotes using the ntile function. This categorization allows for better comparison among movies with varying vote counts.\nI created a density plot using ggplot2 to visualize the distribution of new_rating across the different vote quantiles. This visual representation helps identify how ratings are distributed in relation to the number of votes, offering insight into which movies are considered “solid” based on their vote counts.\n\n\nCode\nggplot(ALL_TITLES, aes(x = new_rating, fill = factor(vote_quantile))) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Density of Ratings by Vote Quantile\",\n       x = \"Rating\",\n       fill = \"Vote Quantile\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nI defined a success metric in the dataset by creating a new column, success_metrics. Movies are assigned a value of 1 if they fall into thehighest vote quantile (quantile 4) and have a new_rating greater than the median new_rating. Otherwise, they are assigned a value of 0. This approach helps categorize movies as “successful” or “not successful” based on a combination of their rating and the number of votes they received.\n\n\nCode\nALL_TITLES &lt;- ALL_TITLES |&gt;\n  mutate(success_metrics = case_when(\n    new_rating &gt; median(new_rating) & vote_quantile==4 ~ 1,\n    TRUE ~ 0\n  ))\nrm(TITLE_EPISODES_2)\n\n\n\n\nCode\nsample_n(ALL_TITLES,100)|&gt;DT::datatable()\n\n\n\n\n\n\n###Examining Success by Genre and Decade\n\n\n\n\n\n\n####Task 4\n\n\n\n\n1.What was the genre with the most “successes” in each decade?\n\nI filtered the ALL_TITLES dataset to create a new dataset called success_projects, containing only the titles marked as successful (where success_metrics equals 1). This dataset was then prepared for further analysis. I also ensured the startYear column was numeric for accurate processing and examined a sample of successful projects.\n\n\nCode\nsuccess_projects=ALL_TITLES|&gt;filter(success_metrics==1)|&gt; \n  mutate(startYear = as.numeric(startYear))\nsample_n(success_projects,100)|&gt;DT::datatable()\n\n\n\n\n\n\n\n\nCode\nsummary(success_projects$startYear)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1878    2003    2013    2008    2018    2024 \n\n\nAfter summarizing the startYear, I removed any duplicate entries and filtered out projects with the genre “Others” to focus on distinct genres. A new column, decade, was created based on the startYear. This column categorizes the years into decades, allowing for easier analysis of trends over time.\n\n\nCode\nsuccess_decade&lt;-success_projects|&gt;identify_title(\"movie\")|&gt;select(startYear,primaryTitle,genre_cleaned)|&gt;\n  arrange(startYear)|&gt;\n  distinct()|&gt;\n  filter(genre_cleaned!=\"Others\")\n\nsuccess_decade &lt;- success_decade |&gt; \n  mutate(decade = case_when(\n  startYear &lt; 1940 ~ \"Before 1940\",\n  startYear &gt;= 1940 & startYear &lt; 1950 ~ \"40's\",\n  startYear &gt;= 1950 & startYear &lt; 1960 ~ \"50's\",\n  startYear &gt;= 1960 & startYear &lt; 1970 ~ \"60's\",\n  startYear &gt;= 1970 & startYear &lt; 1980 ~ \"70's\",\n  startYear &gt;= 1980 & startYear &lt; 1990 ~ \"80's\",\n  startYear &gt;= 1990 & startYear &lt; 2000 ~ \"90's\",\n  startYear &gt;= 2000 & startYear &lt; 2010 ~ \"2000's\",\n  startYear &gt;= 2010 & startYear &lt; 2020 ~ \"2010's\",\n  startYear &gt;= 2020 & startYear &lt; 2030 ~ \"2020's\",\n  TRUE ~ \"N/A\"\n))|&gt;mutate(decade = factor(decade, levels = c(\"Before 1940\", \"40's\", \"50's\", \"60's\", \n                                            \"70's\", \"80's\", \"90's\", \"2000's\", \n                                            \"2010's\", \"2020's\", \"N/A\")))\n\n\nThe resulting cleaned dataset, success_decade, now contains distinct entries of successful movies with their corresponding start years and genres categorized by decade.\n\n\nCode\nlibrary(tidyverse)\nsample_n(success_decade,100)|&gt;DT::datatable()\n\n\n\n\n\n\n\n\nCode\nsuccess_decade |&gt;\n  group_by(decade, genre_cleaned) |&gt;\n  summarize(genre_count = n(), .groups = \"drop\") |&gt;\n  ungroup() |&gt;\n  ggplot(aes(x = reorder(genre_cleaned,genre_count), y =genre_count, fill = genre_cleaned)) + \n  geom_bar(stat = \"identity\", position = \"dodge\") +   # Use bars for better visualization\n  facet_wrap(~decade, scales = \"free_y\") + \n  # Facet by decade to see trends   \n  scale_fill_manual(\"Genres\",values = c(\"Documentary\" = \"#1f77b4\", \"Comedy\" = \"#ff7f0e\", \n                               \"Horror\" = \"#2ca02c\", \"Action\" = \"#d62728\", \n                               \"Adventure\" = \"#9467bd\", \"Crime\" = \"#8c564b\", \n                               \"Animation\" = \"#e377c2\", \"Drama\" = \"#7f7f7f\", \n                               \"Romance\" = \"#bcbd22\", \"Sci-Fi\" = \"#17becf\",\n                               \"Thriller\" = \"#1ae4e2\", \"Biography\" = \"#377eb8\",\n                               \"Musical\" = \"#4daf4a\"))+ #              # Use a color-blind-friendly palette\n  labs(title = \"Number of Movies by Genre Across Decades\",\n       y = \"Number of Movies\", \n       x = \"Decade\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1,size = 6))\n\n\n\n\n\n\n\n\n\n\nsuccess_decade |&gt;\n  group_by(decade, genre_cleaned) |&gt;\n  summarize(genre_count = n(), .groups = \"drop\") |&gt;\n  ungroup()|&gt;group_by(decade) |&gt; \n  slice_max(genre_count, n = 1)\n\n# A tibble: 10 × 3\n# Groups:   decade [10]\n   decade      genre_cleaned genre_count\n   &lt;fct&gt;       &lt;chr&gt;               &lt;int&gt;\n 1 Before 1940 Drama                 230\n 2 40's        Drama                 238\n 3 50's        Drama                 348\n 4 60's        Drama                 461\n 5 70's        Drama                 457\n 6 80's        Drama                 516\n 7 90's        Drama                 742\n 8 2000's      Drama                1163\n 9 2010's      Drama                1508\n10 2020's      Drama                 663\n\n\nIt is Drama category is been the most successes in all decades.\n\n2.What genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\n\nTo analyze the trends in movie genres over time regarding their success, we can examine the average ratings by genre for each decade. This will help us identify which genre has consistently had the most successes and which genre has fallen out of favor over the years.\n\n\nCode\nALL_TITLES &lt;- ALL_TITLES|&gt; mutate(decade = case_when(\n  startYear &lt; 1940 ~ \"Before 1940\",\n  startYear &gt;= 1940 & startYear &lt; 1950 ~ \"40's\",\n  startYear &gt;= 1950 & startYear &lt; 1960 ~ \"50's\",\n  startYear &gt;= 1960 & startYear &lt; 1970 ~ \"60's\",\n  startYear &gt;= 1970 & startYear &lt; 1980 ~ \"70's\",\n  startYear &gt;= 1980 & startYear &lt; 1990 ~ \"80's\",\n  startYear &gt;= 1990 & startYear &lt; 2000 ~ \"90's\",\n  startYear &gt;= 2000 & startYear &lt; 2010 ~ \"2000's\",\n  startYear &gt;= 2010 & startYear &lt; 2020 ~ \"2010's\",\n  startYear &gt;= 2020 & startYear &lt; 2030 ~ \"2020's\",\n  TRUE ~ \"unknown\"\n)) |&gt;\nmutate(decade = factor(decade, levels = c(\"Before 1940\", \"40's\", \"50's\", \"60's\", \n                                            \"70's\", \"80's\", \"90's\", \"2000's\", \n                                            \"2010's\", \"2020's\")))\n\n\n\nALL_MOVIES&lt;-ALL_TITLES|&gt;\n  identify_title(\"movie\")|&gt;\n  select(startYear,decade,primaryTitle,genre_cleaned)|&gt;\n  arrange(startYear)|&gt;\n  distinct()|&gt;\n  filter(genre_cleaned!=\"Others\")|&gt;\n    left_join(ALL_TITLES|&gt;\n                select(startYear,primaryTitle,genre_cleaned,new_rating,success_metrics,numVotes),\n                by=c(\"startYear\"=\"startYear\",\n\"primaryTitle\"=\"primaryTitle\",\"genre_cleaned\"=\"genre_cleaned\"))\n\n\nI then created a new dataset, ALL_MOVIES, which consists of movie titles along with their respective genres, start years, and ratings.\nI calculated the average rating for each genre per decade and filtered out the 2020s to focus on earlier trends. This summary provides insight into how each genre performed over the decades.\n\n\nCode\n# Calculate average rating per genre per decade\nALL_MOVIES |&gt;\n  group_by(genre_cleaned, decade) |&gt;\n  summarise(Average_Rating = median(new_rating))|&gt;ungroup()|&gt;filter(decade!=c(\"2020's\"))|&gt;na.omit()|&gt;\n  \n\nggplot( aes(x = decade, y = Average_Rating, color = decade)) +\n  geom_point() +\n  geom_line(aes(group = genre_cleaned))+\n  facet_wrap(~genre_cleaned, scales = \"free_y\") +  # Facet by genre\n  labs(title = \"Average Movie Rating by Genre and Decade\",\n       x = \"Decade\",\n       y = \"Average Rating\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nDocumentry,Biography and Animation genres consistently produce movies with higher average ratings, typically above 6.5./ On the other hand, Sci-fi,Horror,Thriller present higher risks in terms of audience reception and ratings.These genres were particularly popular in the 1940s and 1950s, a time when they captivated audiences with imaginative storytelling and thrilling experiences. However, over the decades, the landscape of cinema has evolved, and audiences’ tastes have shifted./\nThroughout the decades, Drama has emerged as a dominant genre, enjoying sustained popularity across various eras. However, recent trends indicate that the audience’s appetite for dramatic storytelling may be waning.\n\n3.What genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\nThe analysis reveals the total number of successes for each genre within the specified time frame. By grouping the data by genre_cleaned and success_metrics, we determined how many projects in each genre were classified as successful (success_metrics = 1) compared to non-successful (success_metrics = 0).\n\n\nCode\n# Load necessary library for text annotations\nlibrary(scales)\n\n# Calculate percentages within each genre for success_metrics\nx&lt;-ALL_MOVIES |&gt;\n  filter(decade %in% c(\"2010's\", \"2020's\")) |&gt;\n  group_by(genre_cleaned, success_metrics) |&gt;\n  summarise(count = n())|&gt;\n  mutate(total = sum(count),  # Total per genre\n         percentage = round((count / total) * 100,2)) |&gt;ungroup()\nx|&gt;DT::datatable()\n\n\n\n\n\n\n\n\nCode\n# Create the plot\nggplot(x, aes(x = reorder(genre_cleaned,total), y=total,fill=as.factor(success_metrics))) +\n  geom_bar(stat = \"identity\", position = \"stack\") +  # Bars are dodged side-by-side for success_metrics\n                # Add percentage labels on top of bars\n  labs(title = \"Total number of sucessful genre for 2010's and 2020's\",\n       x = \"Genre\",\n       y = \"Total Number of Movies\",\n       fill = \"Success\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text( hjust = 1,angle=90))\n\n\n\n\n\n\n\n\n\nAt a glance, the analysis indicates that the Drama genre has produced the most successful projects since 2010, followed closely by Comedy and Thriller. However, when we examine the success rate by considering the ratio of successful projects to the total number of projects within each genre, the results shift significantly.\n\n\nCode\n# Create the plot\nggplot(x|&gt;filter(success_metrics==1), aes(x = reorder(genre_cleaned,percentage), y=percentage,fill=genre_cleaned)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  # Bars are dodged side-by-side for success_metrics\n  geom_text(aes(label = paste0(round(percentage, 1), \"%\")),\n            position = position_dodge(width = 0.2), vjust = -0.1) +  # Add percentage labels on top of bars\n  labs(title = \"Percentage of sucessful genre for 2010's and 2020's\",\n       x = \"Genre\",\n       y = \"Percentage of successful movies(%)\",\n       fill = \"Genre\") +\n  theme_minimal() +\n  scale_fill_manual(\"Genres\",values = c(\"Romance\" = \"#1f77b4\", \"Comedy\" = \"#ff7f0e\", \n                               \"Horror\" = \"#2ca02c\", \"Action\" = \"#d62728\", \n                               \"Adventure\" = \"#9467bd\", \"Crime\" = \"#8c564b\", \n                               \"Animation\" = \"#e377c2\", \"Drama\" = \"#7f7f7f\", \n                               \"Documentary\" = \"#bcbd22\", \"Sci-Fi\" = \"#17becf\",\n                               \"Thriller\" = \"#1ae4e2\", \"Biography\" = \"#377eb8\",\n                               \"Musical\" = \"#4daf4a\"))+\n  theme(axis.text.x =element_blank())+\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nBiography, Animation, and Documentary genres emerge as the leaders in terms of success metrics when we look at the proportion of successful films. The disparity between the total number of successful projects in Drama, Comedy, and Thriller versus the success rates in Biography, Animation, and Documentary indicates that while traditional genres like Drama may produce a higher volume of successful films, newer or less conventional genres are achieving a greater proportion of success relative to their output. This suggests that these genres are not only producing fewer films but are also prioritizing quality and engagement, leading to better ratings and audience reception.\n\n4.What genre has become more popular in recent years?\n\n\n\nCode\nif (!require(\"gganimate\")) install.packages(\"gganimate\")\nlibrary(gganimate)\nif (!require(\"scales\")) install.packages(\"scales\")\nlibrary(scales)\nif (!require(\"zoo\")) install.packages(\"zoo\")\nlibrary(zoo)\n\n\n\n\nCode\nyears &lt;- seq(from = 1950, to = 2020, by = 1)\nyears_df &lt;- data.frame(startYear = years)\nALL_MOVIES&lt;-ALL_MOVIES|&gt;mutate(startYear=as.numeric(startYear))\nALL_MOVIES_1 &lt;- full_join(ALL_MOVIES|&gt;filter(startYear&gt;1950), years_df, by = \"startYear\")|&gt;\n  replace_na(list(column_name = 0))  \n\n\n\n\nCode\nALL_MOVIES_1$startYear &lt;- na.approx(ALL_MOVIES_1$startYear)  \nanim &lt;- ALL_MOVIES_1 |&gt;\n  filter(startYear &gt; 1950) |&gt;\n  ggplot(aes(x= new_rating, y= numVotes, color = genre_cleaned)) +\n  geom_point() +\n  scale_y_log10(labels = scales::comma) +  # Log scale for y-axis\n  scale_x_log10(labels = scales::comma) +  # Log scale for x-axis\n  guides(color = \"none\", size = \"none\") +  # Remove legends for color and size\n  theme_bw() +  # Use a clean white background theme\n  facet_wrap(~genre_cleaned) +  # Facet by genre_cleaned\n  ylab(\"Number of Votes\") +\n  xlab(\"Ratings\") +\n  transition_time(startYear) +  # Animate by rounded years\n  ggtitle(\"NumVotes Vs Ratings by Year in {round(frame_time,0)}\") +\n  labs(caption = \"Data from the IMDB DataSet\")\n\n animate(anim, renderer = gifski_renderer(file = paste0(output_dir, \"/animation1.gif\")))\n\n\n\n\n\n\n\n\n\nFrom this graph, we could identify that Dramas,Comedy,Action,Adventure, Crime have been always popular. However, there is a good amount attention being given for Biography and Animations in recent years.\n\n\nVI.Successful Personnel in the Genre\nBased on my findings I have decided to combine Biography Genre and Animation.\nWe focus on the Biography genre to identify high-quality films. The process begins by filtering the ALL_TITLES dataset to select only movies categorized under the Biography genre. The distinct function is used to ensure that each movie is represented only once in the resulting dataset.\n\n\nCode\nbio_anime_movies&lt;-ALL_TITLES|&gt;identify_title(\"movie\")|&gt;filter( genre_cleaned%in% c(\"Biography\",\"Animation\"))|&gt;distinct()\n\nbio_anime_movies &lt;- bio_anime_movies |&gt;filter(vote_quantile&gt;3)|&gt;select(-averageRating,-startYear)|&gt;\n  left_join(ALL_CREW |&gt; filter(!is.na(primaryName)), by = c(\"tconst\" = \"tconst\")) |&gt;\n  distinct()\nsample_n(bio_anime_movies,100)|&gt;DT::datatable()\n\n\n\n\n\n\n\nTask 5:\n\nIdentify (at least) two actors and one director who you will target as the key talent for your movie. Write a short “pitch” as to why they are likely to be successful. You should support your pitch with at least one graphic and one table.\n\n\n\nCode\nbio_anime_movies|&gt;select(primaryName,primaryTitle)|&gt;distinct()|&gt;\n  group_by(primaryName)|&gt;\n  summarize(count=n())|&gt;ungroup()|&gt;arrange(desc(count))\n\n\n# A tibble: 41,171 × 2\n   primaryName        count\n   &lt;chr&gt;              &lt;int&gt;\n 1 Mary Hidalgo          45\n 2 Megumi Hayashibara    44\n 3 Takeshi Seyama        37\n 4 Leslee Feldman        36\n 5 Ikue Ôtani            35\n 6 Avy Kaufman           33\n 7 Ruth Lambert          32\n 8 Kappei Yamaguchi      31\n 9 Mary Vernieu          31\n10 Minami Takayama       30\n# ℹ 41,161 more rows\n\n\n\n\nCode\nfind_projects(\"Mary Hidalgo\")|&gt;identify_title(\"movie\")|&gt; mutate(is_animation = ifelse(genre_cleaned %in% c(\"Animation\",\"Biography\"), 1, 0))|&gt;select(new_rating,numVotes,is_animation,genre_cleaned)|&gt;\n  ggplot(aes(x = new_rating, y = genre_cleaned, color = as.factor(is_animation))) +\n geom_boxplot() +  # Adjust shape for filled points\n  labs(\n    title = \"Mary Hidalgo's Movies Rating Based on Genres\",\n    x = \"Ratings\",\n    y = \"Genre\",\n    color = \"Is_Animation\"\n  ) +\n  \n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nfind_projects(\"Mary Hidalgo\")|&gt;identify_title(\"movie\")|&gt;select(-titleType,-tconst)|&gt;filter(success_metrics==1,genre_cleaned %in% c(\"Biography\",\"Animation\"))|&gt;DT::datatable()\n\n\n\n\n\n\nShe has a lot of box office hits.\nNow I am trying to find actor for my movie.\n#| label: 'Biography Movies Actor'\n#| eval: true\n#| message: false \n#| warning: false\n#| cache: false\n#| code-fold: true\n#|code-summary: \"Show the code\"\n\nbio_anime_movies&lt;-bio_anime_movies|&gt;left_join(TITLE_PRINCIPALS1|&gt;select(nconst,category)|&gt;filter(!is.na(category)),by=c(\"nconst\"=\"nconst\"))|&gt;distinct()\n\n\nbio_anime_movies|&gt;group_by(primaryName,category)|&gt;\nsummarize(count=n(),.groups=\"drop\")|&gt;arrange(desc(count))|&gt;filter(category %in% c(\"actor\",\"director\",\"actress\"))|&gt;\n  slice(1:100)|&gt;DT::datatable()\n#write.csv(bio_anime_movies, \"~/STA9750-2024-FALL/bio_anime_movies.csv\",row.names=TRUE,col.names = TRUE )\nfind_projects(\"Brian Grazer\")|&gt;identify_title(\"movie\")|&gt; mutate(is_biography = ifelse(genre_cleaned == \"Biography\", 1, 0))|&gt;select(new_rating,numVotes,is_biography,genre_cleaned)|&gt;\n  ggplot(aes(x = new_rating, y = genre_cleaned,color=as.factor(is_biography))) +\n geom_boxplot() +  # Adjust shape for filled points\n  labs(\n    title = \"Brian Grazer's Movies Ratings Based on Genres\",\n    x = \"Ratings\",\n    y = \"Genre\",\n    color = \"Is_Biography\"\n  ) +\n  \n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n  \nfind_projects(\"Robert\") |&gt;\n  identify_title(\"movie\") |&gt;\n  mutate(is_biography = ifelse(genre_cleaned == \"Biography\", \"Biography\", \"Others\")) |&gt;\n  select(startYear, numVotes, new_rating, is_biography) |&gt;\n  ggplot(aes(x = startYear, y = new_rating, fill = as.factor(is_biography), size = numVotes)) +\n  geom_point(shape = 21, color = \"black\") +  # Shape 21 allows for point fill with color border\n  labs(\n    title = \"Brian Grazer's Movies Ratings Yearly based on Genre\",\n    x = \"Year\",\n    y = \"New Rating\",\n    fill = \"Is Biography\",\n    size=\"Num of Votes\"\n  ) +\n  scale_fill_manual(values = c(\"Others\" = \"gray\", \"Biography\" = \"blue\")) +  # Correct color mapping\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.border = element_rect(color = \"black\", fill = NA, size = 1)  # Add black borders\n  ) + \n  facet_wrap(~is_biography)\n\n#| label: 'Biography Movies Actoress'\n#| eval: true\n#| message: false \n#| warning: false\n#| cache: false\n#| code-fold: true\n#|code-summary: \"Show the code\"\n\n\n\nbio_anime_movies|&gt;group_by(primaryName,category,decade)|&gt;\nsummarize(count=n(),.groups=\"drop\",ratings=mean(new_rating))|&gt;arrange(desc(decade),desc(count),desc(ratings))|&gt;filter(category==\"actress\")|&gt;\n  #category %in% c(\"actor\",\"director\",\"actress\"))|&gt;\n  slice(1:30)|&gt;DT::datatable()\nfind_projects(\"Sobhita Dhulipala\") |&gt;\n  identify_title(\"movie\") |&gt;\n  mutate(is_biography = ifelse(genre_cleaned == \"Biography\", \"Biography\", \"Others\"))|&gt;  select(startYear, numVotes, new_rating, is_biography)|&gt;\n  ggplot(aes(x = startYear, y = new_rating, fill = as.factor(is_biography), size = numVotes)) +\n  geom_point(shape = 21, color = \"black\") +  # Shape 21 allows for point fill with color border\n  labs(\n    title = \"Sobhita Dhulipala's Movies Ratings Yearly based on Genre\",\n    x = \"Year\",\n    y = \"New Rating\",\n    fill = \"Is Biography\",\n    size=\"Num of Votes\"\n  ) +\n  scale_fill_manual(values = c(\"Others\" = \"gray\", \"Biography\" = \"blue\")) +  # Correct color mapping\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    panel.border = element_rect(color = \"black\", fill = NA, size = 1)  # Add black borders\n  ) + \n  facet_wrap(~is_biography)\n\n\n\n\nVII.Nostalgia and Remakes\n\n\nVIII.Putting It Together"
  }
]